{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Finetuning + Distillation + Quantization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> <b>Data Perparation</b> </h4> \n",
    "<h5> Data Sources </h5>\n",
    "<ol>\n",
    "  <li> <a href=\"https://www.kaggle.com/datasets/sunilthite/llm-detect-ai-generated-text-dataset\"> LLM - Detect AI Generated Text Dataset </a> </li>\n",
    "  <li> <a href=\"https://www.kaggle.com/datasets/thedrcat/daigt-v2-train-dataset\"> DAIGT V2 Train Dataset </a> </li>\n",
    "</ol>\n",
    "\n",
    "<p>Both of these CSV files were added to the following kaggle notebook as an input for merging them and converting them to get our desired output format.</p>\n",
    "<a href=\"https://www.kaggle.com/code/openmihirpatel/aivsog-dataprep\"> Kaggle Notebook for data preparation and preprocessing. </a>\n",
    "<p>After follwoing the notebook a new combined csv file will be generated (in the output folder) which will be our combined training data.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Fine tuning and Distillation</b></h3>\n",
    "<h5><b>Fine Tuning</b></h5><p>We will use <b>BERT-base</b> available on <a href=\"https://huggingface.co/google-bert/bert-base-uncased\"> Hugging Face </a> as our teacher model after finetuning it on our dowstream task (which is Text-Classification).</p>\n",
    "\n",
    "<h5><b>Distillation</b></h5><p>We will use <b>DistilBERT-base</b> available on <a href=\"https://huggingface.co/distilbert/distilbert-base-uncased\"> Hugging Face </a> as our student model for distillation with the help of our teacher model.</p>\n",
    "\n",
    "<p>The following notebook will take us to model distillation and quantization part of this project.</p>\n",
    "<p><b><a href=\"https://www.kaggle.com/code/openmihirpatel/finetuning-and-distillation\">Model Distillation and Quantization</a></b></p>\n",
    "\n",
    "<h5><b>Results discussion</b></h5>\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Model type</th>\n",
    "    <th>Accuracy </th>\n",
    "    <th>Loss </th>\n",
    "    <th>Params </th>\n",
    "    <th>Size (MB)</th>\n",
    "    <th>Time (ms)</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>BERT-base-uncased</td>\n",
    "    <td> 0.993515 </td>\n",
    "    <td> 0.025127 </td>\n",
    "    <td> 109.48 M </td>\n",
    "    <td> 438.003 MB </td>\n",
    "    <td> 495.485 ms </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Distilled-BERT-base-uncased</td>\n",
    "    <td> 0.990813 </td>\n",
    "    <td> 0.040144 </td>\n",
    "    <td> 66.36 M </td>\n",
    "    <td> 265.490 MB </td>\n",
    "    <td> 299.864 ms </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Quantized BERT-base-uncased</td>\n",
    "    <td> 0.997027 </td>\n",
    "    <td> 0.019512 </td>\n",
    "    <td> 109.48 M </td>\n",
    "    <td> 181.483 MB </td>\n",
    "    <td> 340.033 ms </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td> Quantized Distilled-BERT-base-uncased</td>\n",
    "    <td> 0.977033 </td>\n",
    "    <td> 0.065918 </td>\n",
    "    <td> 66.36 M </td>\n",
    "    <td> 138.112 MB </td>\n",
    "    <td> 191.589 ms </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
